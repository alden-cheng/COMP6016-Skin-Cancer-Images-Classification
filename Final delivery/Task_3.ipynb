{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFEikZN3UMsu",
        "outputId": "ea7068c1-ff9a-462a-d9c5-0de1588841fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data process"
      ],
      "metadata": {
        "id": "zf4ca__9e4wr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33o_p9C8e0z1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from tqdm import *\n",
        "import numpy\n",
        "import time\n",
        "import torch\n",
        "from torchvision.models import resnet18, resnet34, resnet50\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = '/content/drive/MyDrive/Dataset/Ham10000/ham10000'\n",
        "label_list = []\n",
        "label_to_image_path_list = {}\n",
        "label_to_int = {}\n",
        "int_to_label = {}"
      ],
      "metadata": {
        "id": "gZjrERuIe9Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load meta data\n",
        "cnt = 0\n",
        "for f1 in os.listdir(data_root):\n",
        "    label = f1\n",
        "    label_to_int[label] = cnt\n",
        "    int_to_label[cnt] = label\n",
        "    cnt += 1\n",
        "    label_list.append(label)\n",
        "    f2 = os.path.join(data_root, f1)\n",
        "    label_to_image_path_list[label] = []\n",
        "    for f3 in os.listdir(f2):\n",
        "        f4 = os.path.join(f2, f3)\n",
        "        label_to_image_path_list[label].append(f4)\n",
        "\n",
        "print( 'label_to_int={0}'.format(label_to_int) )\n",
        "print( 'int_to_label={0}'.format(int_to_label) )"
      ],
      "metadata": {
        "id": "icCDnIKLfAGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbedea7-8086-42f2-dab7-4987c679ed9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label_to_int={'df': 0, 'akiec': 1, 'bcc': 2, 'bkl': 3, 'nv': 4, 'vasc': 5, 'mel': 6}\n",
            "int_to_label={0: 'df', 1: 'akiec', 2: 'bcc', 3: 'bkl', 4: 'nv', 5: 'vasc', 6: 'mel'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load image to color images\n",
        "label_to_image_arr_list = {}\n",
        "for label in label_to_image_path_list:\n",
        "    label_to_image_arr_list[label] = []\n",
        "    image_path_list = label_to_image_path_list[label]\n",
        "    for image_path in tqdm(image_path_list[:10]):\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "        label_to_image_arr_list[label].append(img)\n",
        "\n",
        "# print load status\n",
        "for label in label_to_image_arr_list:\n",
        "    print('{0}: loaded {1} images, shape={2}'.format(label, len(label_to_image_arr_list[label]),\n",
        "                                                    label_to_image_arr_list[label][0].shape))"
      ],
      "metadata": {
        "id": "DcR-9s_7fAnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430c07d5-197f-4ace-da83-9fd01f9218c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:10<00:00,  1.10s/it]\n",
            "100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
            "100%|██████████| 10/10 [00:07<00:00,  1.36it/s]\n",
            "100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.22it/s]\n",
            "100%|██████████| 10/10 [00:05<00:00,  1.99it/s]\n",
            "100%|██████████| 10/10 [00:05<00:00,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df: loaded 10 images, shape=(450, 600, 3)\n",
            "akiec: loaded 10 images, shape=(450, 600, 3)\n",
            "bcc: loaded 10 images, shape=(450, 600, 3)\n",
            "bkl: loaded 10 images, shape=(450, 600, 3)\n",
            "nv: loaded 10 images, shape=(450, 600, 3)\n",
            "vasc: loaded 10 images, shape=(450, 600, 3)\n",
            "mel: loaded 10 images, shape=(450, 600, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# images to x_data, y_data\n",
        "x_data = []\n",
        "y_data = []\n",
        "for label in label_to_image_arr_list:\n",
        "    for img in label_to_image_arr_list[label]:\n",
        "        x_data.append( img )\n",
        "        y_data.append( label_to_int[label] )\n",
        "\n",
        "\n",
        "x_data = numpy.array(x_data)\n",
        "y_data = numpy.array(y_data)\n",
        "print( 'x_data.shape={0}, y_data.shape={1}'.format(x_data.shape, y_data.shape) )"
      ],
      "metadata": {
        "id": "SIiG8XXzfIG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b76f19bf-f1a3-4c2d-c673-d5bf4c4d7a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data.shape=(70, 450, 600, 3), y_data.shape=(70,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet"
      ],
      "metadata": {
        "id": "-VvkMc8ffTJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "class_count = len(label_to_image_arr_list)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# load trained ResNet18 model\n",
        "model = torch.load('/content/drive/MyDrive/Colab Notebooks/Model/1/model_resnet18_task1_1.pth')\n",
        "# model = torch.load('/content/model_resnet18_task1.pth')\n",
        "# Extract the features of trained ResNet18 model from the last CNN layer\n",
        "model_last_cnn = torch.nn.Sequential(  *list(model.children())[:-2] )\n",
        "model_last_cnn.add_module('flatten', torch.nn.Flatten())\n",
        "for para in model_last_cnn.parameters():\n",
        "    para.requires_grad = False"
      ],
      "metadata": {
        "id": "zIDdF-sYfIuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The training and test sets are split in the ratio of 8:2"
      ],
      "metadata": {
        "id": "TAZHx52sfeBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_channel = x_data.shape[-1]\n",
        "n_count = x_data.shape[0]\n",
        "width = x_data.shape[1]\n",
        "height = x_data.shape[2]\n",
        "\n",
        "x_data = x_data.reshape( (n_count,n_channel,width,height)  )\n",
        "print('Before: x_data.shape={0}'.format(x_data.shape))"
      ],
      "metadata": {
        "id": "pSTzksjxfbFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d80ae3-3421-4e3f-cfbb-52e13aeeace9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: x_data.shape=(70, 3, 450, 600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_last_cnn.eval()\n",
        "with torch.no_grad():\n",
        "    x_data_tensor = torch.tensor(x_data, dtype=torch.float32).to(device)\n",
        "    feateures = model_last_cnn(x_data_tensor)\n",
        "    print(feateures.shape)\n",
        "    x_data = feateures\n",
        "#x_data = x_data.reshape((70, 456, 320))\n",
        "print('After: x_data.shape={0}'.format(x_data.shape))\n",
        "\n",
        "\n",
        "# train test split\n",
        "x_train, x_test, y_train, y_test = train_test_split( x_data, y_data,\n",
        "                                                    test_size=0.2, random_state=42 )\n",
        "# output\n",
        "print('x_train={0}, x_test={1}, y_train={2}, y_test={3}'.format(\n",
        "    x_train.shape, x_test.shape, y_train.shape, y_test.shape\n",
        ") )"
      ],
      "metadata": {
        "id": "JLHyu3Dafh0S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "9f5d36c4-6b63-4642-d2a1-48c8a0fde3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bdfdb7819909>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx_data_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfeateures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_last_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeateures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeateures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_acc(y_pred, y_true):\n",
        "    asum = 0\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i]==y_true[i]:\n",
        "            asum += 1\n",
        "    return asum/len(y_pred)"
      ],
      "metadata": {
        "id": "sgFG91gLfjsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and test for each epoch\n",
        "# use these features to train a softmax model\n",
        "# Linear model with softmax\n",
        "class LinearSoftmaxModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearSoftmaxModel, self).__init__()\n",
        "        self.linear = torch.nn.Linear(145920, class_count)\n",
        "    def forward(self, x):\n",
        "        #return torch.nn.functional.softmax(self.linear(x))\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "LtghAyIjflcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_softmax = LinearSoftmaxModel().to(device)\n",
        "# loss and optimizer\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer_function = torch.optim.Adam(model_softmax.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "mi0y-1CdfqIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and test for each epoch\n",
        "epoch = 10\n",
        "batch_size = 64\n",
        "loss_train_history_list = []\n",
        "acc_test_list = []\n",
        "model.to(device)\n",
        "\n",
        "sum_time_cost_train = 0\n",
        "for ep in range(epoch):\n",
        "    i = 0\n",
        "    batch_loss_list = []\n",
        "    t0 = time.time()\n",
        "    while i<len(y_train):\n",
        "        t1 = time.time()\n",
        "\n",
        "        # x_train_tensor_batch = x_train_tensor[i:i+batch_size]\n",
        "        # y_train_tensor_batch = y_train_tensor[i:i+batch_size]\n",
        "        x_train_tensor_batch = x_train[i:i+batch_size]\n",
        "        y_train_tensor_batch = y_train[i:i+batch_size]\n",
        "        x_train_tensor_batch = torch.tensor(x_train_tensor_batch, dtype=torch.float32).to(device)\n",
        "        y_train_tensor_batch = torch.tensor(y_train_tensor_batch, dtype=torch.long).to(device)\n",
        "\n",
        "        # STEP-01: train\n",
        "        model.train()\n",
        "        # predict\n",
        "        #x_train_tensor_batch = x_train_tensor_batch.reshape((1,56,456,320))\n",
        "\n",
        "        y_train_pred = model(x_train_tensor_batch)\n",
        "        # loss\n",
        "        loss = loss_function(y_train_pred, y_train_tensor_batch)\n",
        "        batch_loss_list.append(loss)\n",
        "        # gradient decent\n",
        "        optimizer_function.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_function.step()\n",
        "        i = i+batch_size\n",
        "        t2 = time.time()\n",
        "        print('completed batch {0} of epoch {1}. loss={2}. train batch time cost={3}s'.format(i//batch_size, ep, loss, t2-t1))\n",
        "    t3 = time.time()\n",
        "    sum_time_cost_train += t3-t0\n",
        "\n",
        "    # STEP-02: validation\n",
        "    loss_ave = sum(batch_loss_list)/len(batch_loss_list)\n",
        "    loss_train_history_list.append(loss_ave)\n",
        "\n",
        "    # Test\n",
        "    model.eval()\n",
        "    asum = 0\n",
        "    j=0\n",
        "    with torch.no_grad():\n",
        "        while j < len(y_test):\n",
        "            x_test_batch = x_test[j:j+batch_size]\n",
        "            y_test_batch = y_test[j:j+batch_size]\n",
        "            x_test_tensor_batch = torch.tensor(x_test_batch, dtype=torch.float32).to(device)\n",
        "            y_test_tensor_batch = torch.tensor(y_test_batch, dtype=torch.long).to(device)\n",
        "\n",
        "            y_test_pred_batch = model(x_test_tensor_batch)\n",
        "            y_test_pred_batch = y_test_pred_batch.cpu().detach().numpy()\n",
        "            y_test_pred_batch = numpy.argmax(y_test_pred_batch, axis=1)\n",
        "\n",
        "            for k in range(len(y_test_pred_batch)):\n",
        "                if y_test_pred_batch[k]==y_test_batch[k]:\n",
        "                    asum += 1\n",
        "\n",
        "            j = j+batch_size\n",
        "\n",
        "        t4 = time.time()\n",
        "        acc_test = asum/len(y_test)\n",
        "        print('completed test of epoch {0}. loss={1}. accuracy={2}. train one epoch time cost={3}s, test validation time cost={4}'.format(ep,loss, acc_test, t3-t0, t4-t3))\n",
        "        acc_test_list.append(acc_test)\n",
        "        print(acc_test_list)\n",
        "\n",
        "print(sum_time_cost_train)"
      ],
      "metadata": {
        "id": "OyRyPuVFfr_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tensor_batch.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSElt7WvtotI",
        "outputId": "addef428-e19b-4430-9f84-ce997f52da0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 56, 456, 320])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tensor_batch.reshape((1,56,456,320))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFkpXAiAto5d",
        "outputId": "25121151-17ca-44e3-ea79-af4c101cad11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1021, 0.0000],\n",
              "          [0.0000, 0.0000, 0.5832,  ..., 0.0000, 0.0000, 1.5041],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [0.0673, 1.5487, 1.6204,  ..., 0.0000, 0.0000, 0.9824],\n",
              "          [1.5499, 2.2840, 2.0099,  ..., 0.7675, 1.7061, 5.3534],\n",
              "          [4.1474, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "         [[0.0000, 0.0000, 0.0162,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.2509, 0.0000, 0.2350],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0463, 0.0000, 0.0170]],\n",
              "\n",
              "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0845,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [1.8390, 1.6938, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1166, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0975,  ..., 0.0534, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 2.7996, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [0.3486, 0.0000, 0.8489,  ..., 1.9304, 1.8054, 1.3212],\n",
              "          [1.1262, 1.5405, 1.7007,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 1.1125, 2.1362,  ..., 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "         [[0.0000, 0.0000, 0.0000,  ..., 2.6199, 1.4763, 2.7266],\n",
              "          [1.8588, 1.9908, 0.9146,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0737, 0.4949, 0.0891]],\n",
              "\n",
              "         [[0.0000, 0.0000, 0.0000,  ..., 8.0417, 7.9323, 8.1679],\n",
              "          [6.6496, 5.1343, 4.9853,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.4864, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder path\n",
        "dir_root = '/content/drive/MyDrive/Colab Notebooks/Results/Task 3/1/100/10'\n",
        "if not os.path.exists(dir_root):\n",
        "    os.makedirs(dir_root)\n",
        "\n",
        "loss_train_history_list_txt = os.path.join(dir_root, 'loss_train_history_list.txt')\n",
        "acc_test_list_txt = os.path.join(dir_root, 'acc_test_list.txt')\n",
        "\n",
        "# Open file in write mode\n",
        "with open(loss_train_history_list_txt, 'w') as file:\n",
        "    for item in loss_train_history_list:\n",
        "        file.write(str(item) + '\\n')\n",
        "\n",
        "with open(acc_test_list_txt, 'w') as file:\n",
        "    for item in acc_test_list:\n",
        "        file.write(str(item) + '\\n')"
      ],
      "metadata": {
        "id": "G41Jc2d1f5JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_accuracy = acc_test_list[-1]\n",
        "print(f'Final model accuracy: {final_accuracy:.5f}')"
      ],
      "metadata": {
        "id": "RkDp5ZQVTnML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_history_list_txt =os.path.join(dir_root, 'loss_train_history_list.txt')\n",
        "\n",
        "x_list = []\n",
        "loss_train_history_list = []\n",
        "# Open file in write mode\n",
        "i = 0\n",
        "with open(loss_train_history_list_txt, 'r') as fr:\n",
        "    for line in fr:\n",
        "        i += 1\n",
        "        line = line.strip()\n",
        "        token = float( line.split('(')[1].split(',')[0] )\n",
        "        loss_train_history_list.append(token)\n",
        "        x_list.append(i)\n",
        "\n",
        "# Plotting training loss curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(x_list, loss_train_history_list, label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(dir_root,'training_loss_curve.png'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-iHAdvcHTowf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_test_list_txt = os.path.join(dir_root, 'acc_test_list.txt')\n",
        "x_list = []\n",
        "acc_test_history_list = []\n",
        "# Open file in write mode\n",
        "i = 0\n",
        "with open(acc_test_list_txt, 'r') as fr:\n",
        "    for line in fr:\n",
        "        i += 1\n",
        "        line = line.strip()\n",
        "        token = float( line )\n",
        "        acc_test_history_list.append(token)\n",
        "        x_list.append(i)\n",
        "\n",
        "\n",
        "# Plotting test accuracy curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(x_list, acc_test_history_list, label='Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Test Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(dir_root,'test_accuracy_curve.png'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZOqNlxThaeQl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}